{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCSkGQSZ/nWsuflqixJ83t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/klordo/nlp_homeworks/blob/hw1/hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "До этого не работал в колабе. Читал правила красивого написания для ноутбуков. Как я понял, эти правила для проектов-ноутбуков, но отчасти не для колаба. Потому установки зависимостей делал перед каждым инструментом. Могу исправить и переместить вверх.\n",
        "\n",
        "Пробовал различные инструменты, оставил два варианта:\n",
        "Первый через pymorphy2 и nltk без удаления стоп слов.\n",
        "Второй через spacy.\n",
        "Не решил одну проблему, о которой написал в самом конце.\n",
        "\n",
        "Если нужны будут исправления, то хотел бы доделать до максимального балла, если это возможно)"
      ],
      "metadata": {
        "id": "zZ9nxxCYvcey"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBUcjVc9gLcM"
      },
      "outputs": [],
      "source": [
        "!pip install corus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.1/lenta-ru-news.csv.bz2"
      ],
      "metadata": {
        "id": "2o8Fwc2E1Fr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from corus import load_lenta2\n",
        "\n",
        "path = 'lenta-ru-news.csv.bz2'\n",
        "records = load_lenta2(path)"
      ],
      "metadata": {
        "id": "2pPoA8lItiM-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [next(records).text for i in range(1000)]\n",
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "cuwIoqnd_EzO",
        "outputId": "f9c46bf6-e3f7-4fb1-b7f0-479e42011b9f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Бои у Сопоцкина и Друскеник закончились отступлением германцев. Неприятель, приблизившись с севера к Осовцу начал артиллерийскую борьбу с крепостью. В артиллерийском бою принимают участие тяжелые калибры. С раннего утра 14 сентября огонь достиг значительного напряжения. Попытка германской пехоты пробиться ближе к крепости отражена. В Галиции мы заняли Дембицу. Большая колонна, отступавшая по шоссе от Перемышля к Саноку, обстреливалась с высот нашей батареей и бежала, бросив парки, обоз и автомобили. Вылазки гарнизона Перемышля остаются безуспешными. При продолжающемся отступлении австрийцев обнаруживается полное перемешивание их частей, захватываются новые партии пленных, орудия и прочая материальная часть. На перевале Ужок мы разбили неприятельский отряд, взяли его артиллерию и много пленных и, продолжая преследовать, вступили в пределы Венгрии. «Русский инвалид», 16 сентября 1914 года.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install clean-text"
      ],
      "metadata": {
        "id": "uTc4iorOeg-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from cleantext import replace_emails, replace_numbers, replace_urls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKcPmuWXea-v",
        "outputId": "8224e031-02a1-4561-dea7-7ec8c1c467a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавил пробелы, потому что слова ниже были иногда присоединенные вплотную без пробела к другим словам.\n",
        "Хотел добавить символы \"<>\", но они образовывали отдельные токены."
      ],
      "metadata": {
        "id": "eQBVgzAa3w4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_clean = dataset.copy()\n",
        "dataset_clean = [replace_emails(text, ' email ') for text in dataset_clean]\n",
        "dataset_clean = [replace_numbers(text, ' number ') for text in dataset_clean]\n",
        "dataset_clean = [replace_urls(text, ' url ') for text in dataset_clean]"
      ],
      "metadata": {
        "id": "eRAfWggF84Dy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "oNPkFa2FT4M9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbols = set()\n",
        "for text in dataset_clean:\n",
        "    for char in text:\n",
        "        if not char.isalpha() and not char.isdigit() and char not in ' .,!?':\n",
        "            symbols.add(char)\n",
        "symbols"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmtJAa-GTybS",
        "outputId": "f98da7a1-fc93-4ae5-bfd7-cfce5c4ef689"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\"',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " '-',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '=',\n",
              " '\\xa0',\n",
              " '«',\n",
              " '»',\n",
              " '–',\n",
              " '—',\n",
              " '’',\n",
              " '…',\n",
              " '№'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = r'[^\\w\\s\\d.,!?]+'\n",
        "dataset_clean = [re.sub(pattern, '', text) for text in dataset_clean]"
      ],
      "metadata": {
        "id": "222Dvy9K0fAX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_clean[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "rRVggkdK145b",
        "outputId": "6ee43182-f8cd-4348-90e3-5c29feba3622"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Бои у Сопоцкина и Друскеник закончились отступлением германцев. Неприятель, приблизившись с севера к Осовцу начал артиллерийскую борьбу с крепостью. В артиллерийском бою принимают участие тяжелые калибры. С раннего утра  number  сентября огонь достиг значительного напряжения. Попытка германской пехоты пробиться ближе к крепости отражена. В Галиции мы заняли Дембицу. Большая колонна, отступавшая по шоссе от Перемышля к Саноку, обстреливалась с высот нашей батареей и бежала, бросив парки, обоз и автомобили. Вылазки гарнизона Перемышля остаются безуспешными. При продолжающемся отступлении австрийцев обнаруживается полное перемешивание их частей, захватываются новые партии пленных, орудия и прочая материальная часть. На перевале Ужок мы разбили неприятельский отряд, взяли его артиллерию и много пленных и, продолжая преследовать, вступили в пределы Венгрии. Русский инвалид,  number  сентября  number  года.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nltk и pymorphy2"
      ],
      "metadata": {
        "id": "YPJr1AajtNhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdUM092dCf5n",
        "outputId": "b93c926d-40a9-4b8e-f2fe-a9e1489ee4f5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import (\n",
        "    sent_tokenize,\n",
        "    word_tokenize,\n",
        ")"
      ],
      "metadata": {
        "id": "6CXkMekjCfve"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данным инструментом решил разделить список документов по спискам предложений, каждый из которых делится на списки слов."
      ],
      "metadata": {
        "id": "_sCyD0yD6LUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_tokenized = [[word_tokenize(sent, language='russian') for sent in sent_tokenize(text, language='russian')] for text in dataset_clean]\n",
        "dataset_tokenized[0][:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IDEzzjYcfwU",
        "outputId": "dfaad8aa-f8ee-4f55-fe89-07458a258cf5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Бои',\n",
              "  'у',\n",
              "  'Сопоцкина',\n",
              "  'и',\n",
              "  'Друскеник',\n",
              "  'закончились',\n",
              "  'отступлением',\n",
              "  'германцев',\n",
              "  '.'],\n",
              " ['Неприятель',\n",
              "  ',',\n",
              "  'приблизившись',\n",
              "  'с',\n",
              "  'севера',\n",
              "  'к',\n",
              "  'Осовцу',\n",
              "  'начал',\n",
              "  'артиллерийскую',\n",
              "  'борьбу',\n",
              "  'с',\n",
              "  'крепостью',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "С помощью pymorphy2 провел лемматизацию без удаления стоп слов."
      ],
      "metadata": {
        "id": "MEGkbLgFqSfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy2"
      ],
      "metadata": {
        "id": "RXDK7YxoaOOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy2"
      ],
      "metadata": {
        "id": "Uzx3WAEdaWi9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "metadata": {
        "id": "czWHoBATa9tu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_lemmatized = [[[morph.parse(word)[0].normal_form for word in sent] for sent in text] for text in dataset_tokenized]"
      ],
      "metadata": {
        "id": "OkHlsXtjgX9U"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_lemmatized[0][:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNbQ_zgqhUQ0",
        "outputId": "b50e6862-41fa-4d29-96c6-7f3012609be4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['бой',\n",
              "  'у',\n",
              "  'сопоцкина',\n",
              "  'и',\n",
              "  'друскеник',\n",
              "  'закончиться',\n",
              "  'отступление',\n",
              "  'германец',\n",
              "  '.'],\n",
              " ['неприятель',\n",
              "  ',',\n",
              "  'приблизиться',\n",
              "  'с',\n",
              "  'север',\n",
              "  'к',\n",
              "  'осовца',\n",
              "  'начать',\n",
              "  'артиллерийский',\n",
              "  'борьба',\n",
              "  'с',\n",
              "  'крепость',\n",
              "  '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вариант с помощью spacy для токенизации, лемматизации и удаления стоп слов."
      ],
      "metadata": {
        "id": "dpzXFGWuuGBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "mTaHwPAqjFsT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m spacy download ru_core_news_sm"
      ],
      "metadata": {
        "id": "6RwiOA45jKh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"ru_core_news_sm\")"
      ],
      "metadata": {
        "id": "KMjKNyQMjPXP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_doc = [[token.lemma_ for token in nlp(doc) if not token.is_stop] for doc in dataset_clean]"
      ],
      "metadata": {
        "id": "36lShg_BkNab"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_doc[0][:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCqtA4DSodMB",
        "outputId": "3ba1b304-0e83-4b53-fbd6-9fac177a7c81"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['бой',\n",
              " 'сопоцкина',\n",
              " 'друскеник',\n",
              " 'закончиться',\n",
              " 'отступление',\n",
              " 'германец',\n",
              " '.',\n",
              " 'неприятель',\n",
              " ',',\n",
              " 'приблизиться']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "4yFYko3ePQN5"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad_tokens = set()\n",
        "for i, text in enumerate(dataset_doc):\n",
        "    for word in text:\n",
        "        if re.search(r'[^a-zA-Zа-яА-ЯёЁ]', word) and word not in '.,!?':\n",
        "            bad_tokens.add(word)\n",
        "\n",
        "list(bad_tokens)[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5Od878jNgU8",
        "outputId": "18567a50-0f4b-43ea-e488-cea451cdbd2d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.com',\n",
              " '..',\n",
              " 'существования,340',\n",
              " 'т.е.',\n",
              " '12сентября',\n",
              " 'w.t.f.r.c.',\n",
              " 'января1999',\n",
              " '.00закрываются',\n",
              " 'с.петербурга',\n",
              " 'в.матвиенко',\n",
              " '.Ru',\n",
              " 'id3',\n",
              " 'декабря1998',\n",
              " '26полнометражных',\n",
              " '2428сделки',\n",
              " 'ст.',\n",
              " 'в.у.',\n",
              " 'г.',\n",
              " 'сб.',\n",
              " 'п.']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Решил убрать плохие токены. Либо детально очищать текст, либо потерять часть информации. Я выбрал второе. Таких токенов по сравнению с размером датасета в целом не так много."
      ],
      "metadata": {
        "id": "2W_jb_7Q6MBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_doc = [[word for word in text if word not in bad_tokens] for text in dataset_doc]"
      ],
      "metadata": {
        "id": "rbrpGSxQ6J8D"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Не решенная проблема - многие слова не разделены пробелами."
      ],
      "metadata": {
        "id": "taJ3uuHT5ijF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in dataset_doc[:10]:\n",
        "  for token in doc:\n",
        "    if len(token) > 20:\n",
        "      print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCJ6UI_nwqxo",
        "outputId": "f82f1bec-2b80-4340-bab4-48f83dfde92c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "фотографкорреспондент\n",
            "воротамкенсингтонского\n",
            "сдержаннойпоминальной\n",
            "оглашеныокончательные\n",
            "французскиеследователи\n",
            "обвиненийфотографампапарацци\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordninja"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37aq7V-4zimP",
        "outputId": "20725de7-e9e5-43d4-e383-825aed2d9363"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wordninja in /usr/local/lib/python3.10/dist-packages (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wordninja"
      ],
      "metadata": {
        "id": "C_m31x3e0VTM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'этоттекстнеразделенпробелами'\n",
        "words = wordninja.split(text)\n",
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA7gNgS_4Xbj",
        "outputId": "0acd2bf9-e7e9-48e6-a84f-22e9636c74d8"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Необходимо перевести модель на русскую, но я пока не нашел способ как ее найти и скачать в колаб...\n",
        "\n",
        "Как я понял, необходимо для этого найти руский словарь."
      ],
      "metadata": {
        "id": "Nm0qPMCH4nop"
      }
    }
  ]
}